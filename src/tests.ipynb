{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9870c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.rnn import CRNN_Model\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from neurokit2 import ecg\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import stumpy\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLING_RATE = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edff6a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "if (!(\"Notification\" in window)) {\n    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n    Notification.requestPermission(function (permission) {\n        if(!('permission' in Notification)) {\n            Notification.permission = permission;\n        }\n    })\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals shape: torch.Size([8, 12, 10000])\n",
      "Labels: tensor([0, 1, 2, 1, 3, 1, 3, 0])\n",
      "ECG IDs: ('473622.parquet.gzip', '379657.parquet.gzip', '357500.parquet.gzip', '264472.parquet.gzip', '262041.parquet.gzip', '502202.parquet.gzip', '534546.parquet.gzip', '327277.parquet.gzip')\n"
     ]
    }
   ],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data_folder, class_folders, files_per_class=200, mp_window = 1000):\n",
    "        self.samples = []\n",
    "        self.leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "        self.mp_window = mp_window\n",
    "        for folder, label in class_folders.items():\n",
    "            files = glob.glob(os.path.join(data_folder, folder, '*.parquet.gzip'))\n",
    "            # enforce exact files_per_class per class (downsample or upsample with replacement)\n",
    "            if len(files) >= files_per_class:\n",
    "                files = random.sample(files, files_per_class)\n",
    "            else:\n",
    "                files = random.choices(files, k=files_per_class)\n",
    "\n",
    "            for f in files:\n",
    "                try:\n",
    "                    df = pd.read_parquet(f, engine='fastparquet')\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to read {f}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # ensure required lead columns exist\n",
    "                if not set(self.leads).issubset(df.columns):\n",
    "                    print(f\"Missing leads in {f}, skipping\")\n",
    "                    continue\n",
    "\n",
    "                # convert lead columns to numeric, coerce non-numeric to NaN, then fill and cast\n",
    "                df_leads = df[self.leads].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "\n",
    "                # shape -> (12, time)\n",
    "                signal = df_leads.values.T\n",
    "\n",
    "                matrix_profiles = []\n",
    "                for i in range(signal.shape[0]):\n",
    "                    mp = stumpy.stump(signal[i].astype(np.float64), m=self.mp_window)[:, 0].astype(np.float32)\n",
    "                    pad_width = signal.shape[1] - len(mp)\n",
    "                    padded_mp = np.pad(mp, (0, pad_width), 'constant', constant_values=0)\n",
    "                    padded_mp[np.isinf(padded_mp)] = 1e9\n",
    "                    matrix_profiles.append(padded_mp)\n",
    "                matrix_profiles_np = np.array(matrix_profiles, dtype=np.float32)\n",
    "                combined_signal = np.concatenate((signal, matrix_profiles_np), axis=0)\n",
    "                # self.samples.append((torch.tensor(combined_signal, dtype=torch.float32), label, os.path.basename(f)))\n",
    "                self.samples.append((torch.tensor(matrix_profiles_np, dtype=torch.float32), label, os.path.basename(f)))\n",
    "                # self.samples.append((torch.tensor(signal, dtype=torch.float32), label, os.path.basename(f)))\n",
    "    def process_file(self, f, label):\n",
    "        try:\n",
    "            df = pd.read_parquet(f, engine='fastparquet')\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {f}: {e}\")\n",
    "            return None\n",
    "        \n",
    "        if not set(self.leads).issubset(df.columns):\n",
    "            print(f\"Missing leads in {f}, skipping\")\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal, label, ecg_id = self.samples[idx]\n",
    "        return signal, label, ecg_id\n",
    "\n",
    "# Usage example\n",
    "class_folders = {\n",
    "    'arritmia': 0,\n",
    "    'block': 1,\n",
    "    'fibrilation': 2,\n",
    "    'normal': 3\n",
    "}\n",
    "data_folder = 'data'\n",
    "dataset = ECGDataset(data_folder, class_folders, files_per_class=10)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Inspect one batch\n",
    "for signals, labels, ecg_ids in dataloader:\n",
    "    print('Signals shape:', signals.shape)  # (batch, 12, time)\n",
    "    print('Labels:', labels)\n",
    "    print('ECG IDs:', ecg_ids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f7abe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 200 samples + split indices to loader12MP_CRNN.pth\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "labels_arr = [dataset.samples[i][1] for i in indices]\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=labels_arr, random_state=42)\n",
    "\n",
    "serializable = {\n",
    "    'samples': [(sig.cpu().numpy(), int(label), str(ecg_id)) for sig, label, ecg_id in dataset.samples],\n",
    "    'train_idx': train_idx,\n",
    "    'val_idx': val_idx,\n",
    "    'leads': dataset.leads,\n",
    "    'mp_window': dataset.mp_window\n",
    "}\n",
    "torch.save(serializable, 'loader12MP_CRNN.pth')\n",
    "print(f\"Saved {len(serializable['samples'])} samples + split indices to loader12MP_CRNN.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fbb47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data from loader12MP_CRNN.pth...\n",
      "Loaded 200 total samples.\n",
      "Training samples: 160, Validation samples: 40\n",
      "\n",
      "DataLoaders created successfully.\n",
      "Sample batch shape: torch.Size([8, 24, 10000])\n",
      "Sample batch labels: tensor([2, 0, 3, 1, 2, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "class PreloadedECGDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        # Convert numpy arrays back to tensors\n",
    "        self.samples = [(torch.tensor(sig, dtype=torch.float32), label, ecg_id) for sig, label, ecg_id in samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# --- Load the pre-processed data ---\n",
    "print(\"Loading pre-processed data from loader12MP_CRNN.pth...\")\n",
    "loaded_data = torch.load('loader12MP_CRNN.pth', weights_only=False)\n",
    "\n",
    "# Extract the components\n",
    "all_samples = loaded_data['samples']\n",
    "train_idx = loaded_data['train_idx']\n",
    "val_idx = loaded_data['val_idx']\n",
    "\n",
    "print(f\"Loaded {len(all_samples)} total samples.\")\n",
    "print(f\"Training samples: {len(train_idx)}, Validation samples: {len(val_idx)}\")\n",
    "\n",
    "# --- Create Datasets and DataLoaders ---\n",
    "# Create a full dataset object from the loaded samples\n",
    "full_dataset = PreloadedECGDataset(all_samples)\n",
    "\n",
    "# Create subsets for training and validation using the saved indices\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset, val_idx)\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"\\nDataLoaders created successfully.\")\n",
    "\n",
    "# Optional: Inspect a batch to verify\n",
    "signals, labels, ids = next(iter(train_loader))\n",
    "print(f\"Sample batch shape: {signals.shape}\")\n",
    "print(f\"Sample batch labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d5cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, mode='min', checkpoint_path='best_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.counter = 0\n",
    "        self.best_score = np.inf if mode == 'min' else -np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score, model):\n",
    "        is_better = False\n",
    "        if self.mode == 'min':\n",
    "            is_better = current_score < (self.best_score - self.min_delta)\n",
    "        else:\n",
    "            is_better = current_score > (self.best_score + self.min_delta)\n",
    "\n",
    "        if is_better:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "            print(f\"Mejora detectada. Guardando modelo en {self.checkpoint_path}\")\n",
    "            torch.save(model.state_dict(), self.checkpoint_path)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"Sin mejora. Contador de paciencia: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                print(\"--- EARLY STOPPING ACTIVADO ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f62b31",
   "metadata": {},
   "source": [
    "ECG eliminados por peso (2kb):\n",
    "\n",
    "- block: 8846, 314864\n",
    "- normal: 74424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e47902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando entrenamiento de CRNN en cpu ---\n",
      "Epoch 1/100 | Train Loss: 1.4112 - Train Acc: 0.1875 | Val Loss: 1.3872 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 2/100 | Train Loss: 1.3907 - Train Acc: 0.1250 | Val Loss: 1.3870 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 3/100 | Train Loss: 1.3957 - Train Acc: 0.2812 | Val Loss: 1.3868 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 4/100 | Train Loss: 1.3998 - Train Acc: 0.1875 | Val Loss: 1.3867 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 5/100 | Train Loss: 1.3899 - Train Acc: 0.2500 | Val Loss: 1.3869 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 1 / 10\n",
      "Epoch 6/100 | Train Loss: 1.3937 - Train Acc: 0.3125 | Val Loss: 1.3865 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 7/100 | Train Loss: 1.4015 - Train Acc: 0.0938 | Val Loss: 1.3865 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 8/100 | Train Loss: 1.3970 - Train Acc: 0.1250 | Val Loss: 1.3863 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 9/100 | Train Loss: 1.3945 - Train Acc: 0.2188 | Val Loss: 1.3861 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 10/100 | Train Loss: 1.3862 - Train Acc: 0.1562 | Val Loss: 1.3848 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 11/100 | Train Loss: 1.3863 - Train Acc: 0.3125 | Val Loss: 1.3844 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 12/100 | Train Loss: 1.3831 - Train Acc: 0.2188 | Val Loss: 1.3841 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 13/100 | Train Loss: 1.3880 - Train Acc: 0.2188 | Val Loss: 1.3832 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 14/100 | Train Loss: 1.3816 - Train Acc: 0.2500 | Val Loss: 1.3822 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 15/100 | Train Loss: 1.3793 - Train Acc: 0.2500 | Val Loss: 1.3796 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 16/100 | Train Loss: 1.3725 - Train Acc: 0.3438 | Val Loss: 1.3729 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 17/100 | Train Loss: 1.3694 - Train Acc: 0.4062 | Val Loss: 1.3726 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 18/100 | Train Loss: 1.3638 - Train Acc: 0.4375 | Val Loss: 1.3770 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 1 / 10\n",
      "Epoch 19/100 | Train Loss: 1.3614 - Train Acc: 0.3438 | Val Loss: 1.3879 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 2 / 10\n",
      "Epoch 20/100 | Train Loss: 1.3570 - Train Acc: 0.4062 | Val Loss: 1.3562 - Val Acc: 0.2500\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 21/100 | Train Loss: 1.3657 - Train Acc: 0.2812 | Val Loss: 1.3469 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 22/100 | Train Loss: 1.3491 - Train Acc: 0.4375 | Val Loss: 1.3414 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 23/100 | Train Loss: 1.3279 - Train Acc: 0.5625 | Val Loss: 1.3391 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 24/100 | Train Loss: 1.3388 - Train Acc: 0.4062 | Val Loss: 1.3322 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 25/100 | Train Loss: 1.3367 - Train Acc: 0.3438 | Val Loss: 1.3203 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 26/100 | Train Loss: 1.3038 - Train Acc: 0.5312 | Val Loss: 1.3335 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 1 / 10\n",
      "Epoch 27/100 | Train Loss: 1.3089 - Train Acc: 0.4062 | Val Loss: 1.3170 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 28/100 | Train Loss: 1.2868 - Train Acc: 0.4688 | Val Loss: 1.2875 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 29/100 | Train Loss: 1.3023 - Train Acc: 0.4375 | Val Loss: 1.2541 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 30/100 | Train Loss: 1.2589 - Train Acc: 0.5312 | Val Loss: 1.2490 - Val Acc: 0.5000\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 31/100 | Train Loss: 1.2379 - Train Acc: 0.4375 | Val Loss: 1.2507 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 1 / 10\n",
      "Epoch 32/100 | Train Loss: 1.2134 - Train Acc: 0.4062 | Val Loss: 1.2881 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 2 / 10\n",
      "Epoch 33/100 | Train Loss: 1.2171 - Train Acc: 0.4688 | Val Loss: 1.2562 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 3 / 10\n",
      "Epoch 34/100 | Train Loss: 1.1831 - Train Acc: 0.4688 | Val Loss: 1.3790 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 4 / 10\n",
      "Epoch 35/100 | Train Loss: 1.1538 - Train Acc: 0.4688 | Val Loss: 1.3940 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 5 / 10\n",
      "Epoch 36/100 | Train Loss: 1.1977 - Train Acc: 0.4062 | Val Loss: 1.2932 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 6 / 10\n",
      "Epoch 37/100 | Train Loss: 1.1084 - Train Acc: 0.5312 | Val Loss: 1.3934 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 7 / 10\n",
      "Epoch 38/100 | Train Loss: 1.0689 - Train Acc: 0.5000 | Val Loss: 1.1662 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 39/100 | Train Loss: 1.1346 - Train Acc: 0.5000 | Val Loss: 1.1625 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 40/100 | Train Loss: 1.0725 - Train Acc: 0.5312 | Val Loss: 1.1741 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 1 / 10\n",
      "Epoch 41/100 | Train Loss: 1.2392 - Train Acc: 0.2188 | Val Loss: 1.2656 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 2 / 10\n",
      "Epoch 42/100 | Train Loss: 1.0504 - Train Acc: 0.5625 | Val Loss: 1.1542 - Val Acc: 0.5000\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 43/100 | Train Loss: 1.0407 - Train Acc: 0.3750 | Val Loss: 1.1284 - Val Acc: 0.5000\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 44/100 | Train Loss: 1.1899 - Train Acc: 0.3438 | Val Loss: 1.1179 - Val Acc: 0.3750\n",
      "Mejora detectada. Guardando modelo en crnn_stumpy.pth\n",
      "Epoch 45/100 | Train Loss: 1.1345 - Train Acc: 0.4062 | Val Loss: 1.1749 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 1 / 10\n",
      "Epoch 46/100 | Train Loss: 1.0605 - Train Acc: 0.5625 | Val Loss: 1.3511 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 2 / 10\n",
      "Epoch 47/100 | Train Loss: 1.0351 - Train Acc: 0.4688 | Val Loss: 1.3829 - Val Acc: 0.1250\n",
      "Sin mejora. Contador de paciencia: 3 / 10\n",
      "Epoch 48/100 | Train Loss: 1.1031 - Train Acc: 0.5000 | Val Loss: 1.2366 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 4 / 10\n",
      "Epoch 49/100 | Train Loss: 0.9564 - Train Acc: 0.5625 | Val Loss: 1.1911 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 5 / 10\n",
      "Epoch 50/100 | Train Loss: 1.0660 - Train Acc: 0.4375 | Val Loss: 1.1927 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 6 / 10\n",
      "Epoch 51/100 | Train Loss: 1.0147 - Train Acc: 0.5000 | Val Loss: 1.2082 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 7 / 10\n",
      "Epoch 52/100 | Train Loss: 1.0127 - Train Acc: 0.5312 | Val Loss: 1.2137 - Val Acc: 0.1250\n",
      "Sin mejora. Contador de paciencia: 8 / 10\n",
      "Epoch 53/100 | Train Loss: 0.9520 - Train Acc: 0.5625 | Val Loss: 1.2418 - Val Acc: 0.2500\n",
      "Sin mejora. Contador de paciencia: 9 / 10\n",
      "Epoch 54/100 | Train Loss: 0.9440 - Train Acc: 0.5000 | Val Loss: 1.2744 - Val Acc: 0.3750\n",
      "Sin mejora. Contador de paciencia: 10 / 10\n",
      "--- EARLY STOPPING ACTIVADO ---\n",
      "Deteniendo el entrenamiento anticipadamente.\n",
      "--- Entrenamiento Finalizado ---\n",
      "Cargando el mejor modelo desde crnn_stumpy.pth (Mejor Val Loss: 1.117889)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "$(document).ready(\n    function() {\n        function appendUniqueDiv(){\n            // append a div with our uuid so we can check that it's already\n            // been sent and avoid duplicates on page reload\n            var notifiedDiv = document.createElement(\"div\")\n            notifiedDiv.id = \"1d403217-60ae-4ed8-acea-c87b06e4f325\"\n            element.append(notifiedDiv)\n        }\n\n        // only send notifications if the pageload is complete; this will\n        // help stop extra notifications when a saved notebook is loaded,\n        // which during testing gives us state \"interactive\", not \"complete\"\n        if (document.readyState === 'complete') {\n            // check for the div that signifies that the notification\n            // was already sent\n            if (document.getElementById(\"1d403217-60ae-4ed8-acea-c87b06e4f325\") === null) {\n                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n                if (Notification.permission !== 'denied') {\n                    if (Notification.permission !== 'granted') { \n                        Notification.requestPermission(function (permission) {\n                            if(!('permission' in Notification)) {\n                                Notification.permission = permission\n                            }\n                        })\n                    }\n                    if (Notification.permission === 'granted') {\n                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n                    appendUniqueDiv()\n                    notification.onclick = function () {\n                        window.focus();\n                        this.close();\n                        };\n                    } \n                }     \n            }\n        }\n    }\n)\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "indices = list(range(len(dataset)))\n",
    "labels_arr = [dataset.samples[i][1] for i in indices]\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=labels_arr, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CRNN_Model(\n",
    "    n_channels_cnn=12,\n",
    "    rnn_hidden_size=128, \n",
    "    rnn_num_layers=2,    \n",
    "    num_classes=4,\n",
    "    bidirectional=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "early_stopper = EarlyStopping(patience=10, mode='min', checkpoint_path='crnn_stumpy.pth')\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "print(f\"--- Iniciando entrenamiento de CRNN en {device} ---\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    \n",
    "    for signals, labels, ids in train_loader:\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(signals) \n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item() * signals.size(0)\n",
    "        total_train += signals.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        \n",
    "    train_acc = correct_train / total_train if total_train else 0.0\n",
    "    avg_train_loss = total_train_loss / total_train if total_train else 0.0\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    total_val = 0\n",
    "    correct_val = 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for signals, labels, ids in val_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(signals)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            total_val_loss += loss.item() * signals.size(0)\n",
    "            \n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_val += signals.size(0)\n",
    "            correct_val += (preds == labels).sum().item()\n",
    "            \n",
    "    val_acc = correct_val / total_val if total_val else 0.0\n",
    "    avg_val_loss = total_val_loss / total_val if total_val else 0.0\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} - Train Acc: {train_acc:.4f} | Val Loss: {avg_val_loss:.4f} - Val Acc: {val_acc:.4f}')\n",
    "    early_stopper(avg_val_loss, model)\n",
    "    \n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Deteniendo el entrenamiento anticipadamente.\")\n",
    "        break\n",
    "\n",
    "print(\"--- Entrenamiento Finalizado ---\")\n",
    "\n",
    "print(f\"Cargando el mejor modelo desde {early_stopper.checkpoint_path} (Mejor Val Loss: {early_stopper.best_score:.6f})\")\n",
    "model.load_state_dict(torch.load(early_stopper.checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484ef8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f100c7c4",
   "metadata": {},
   "source": [
    "Epoch 16/100 | Train Loss: 0.4743 - Train Acc: 0.8200 | Val Loss: 0.4341 - Val Acc: 0.8293\n",
    "Mejora detectada. Guardando modelo en crnn_best_model.pth\n",
    "\n",
    "\n",
    "\n",
    "Epoch 25/100 | Train Loss: 0.4435 - Train Acc: 0.8307 | Val Loss: 0.4710 - Val Acc: 0.8236\n",
    "Mejora detectada. Guardando modelo en crnn_stumpy.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b993951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'mp_I', 'mp_II', 'mp_III', 'mp_aVR', 'mp_aVL', 'mp_aVF', 'mp_V1', 'mp_V2', 'mp_V3', 'mp_V4', 'mp_V5', 'mp_V6']\n",
      "Cargando datos...\n",
      "Background signals shape: torch.Size([8, 24, 10000])\n",
      "Test signals shape: torch.Size([8, 24, 10000])\n",
      "Cargando modelo...\n",
      "Modelo cargado exitosamente.\n",
      "Calculando SHAP values (esto puede tardar)...\n",
      "Cálculo de SHAP finalizado.\n",
      "SHAP values tiene 8 elementos (uno por clase)\n",
      "El shape de los SHAP para la clase 0 es: (24, 10000, 4)\n",
      "\n",
      "--- Importancia Absoluta Media por Lead ---\n",
      "mp_aVR: 0.000084\n",
      "mp_V2: 0.000082\n",
      "V2: 0.000081\n",
      "mp_V6: 0.000080\n",
      "mp_aVF: 0.000080\n",
      "V6: 0.000076\n",
      "mp_V4: 0.000074\n",
      "aVR: 0.000074\n",
      "mp_V1: 0.000072\n",
      "mp_aVL: 0.000070\n",
      "V4: 0.000069\n",
      "mp_II: 0.000069\n",
      "mp_V3: 0.000066\n",
      "mp_III: 0.000065\n",
      "mp_V5: 0.000063\n",
      "aVF: 0.000060\n",
      "V3: 0.000060\n",
      "mp_I: 0.000060\n",
      "aVL: 0.000059\n",
      "II: 0.000058\n",
      "V1: 0.000057\n",
      "III: 0.000057\n",
      "I: 0.000054\n",
      "V5: 0.000048\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap  # Necesitarás instalarlo: pip install shap\n",
    "from models.rnn import CRNN_Model\n",
    "\n",
    "# --- PARÁMETROS ---\n",
    "N_CHANNELS = 24  # <-- ¡Asegúrate que coincida con el modelo guardado!\n",
    "NUM_CLASSES = 4\n",
    "RNN_HIDDEN = 128\n",
    "RNN_LAYERS = 2\n",
    "MODEL_PATH = 'crnn_stumpy.pth' # <-- El path de tu notebook\n",
    "DATA_FOLDER = 'data'\n",
    "LEADS = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "mp = ['mp_' + i for i in LEADS]\n",
    "LEADS = LEADS + mp\n",
    "print(LEADS)\n",
    "\n",
    "CLASS_FOLDERS = {\n",
    "    'arritmia': 0,\n",
    "    'block': 1,\n",
    "    'fibrilation': 2,\n",
    "    'normal': 3\n",
    "}\n",
    "\n",
    "# --- 1. Cargar Datos para SHAP ---\n",
    "print(\"Cargando datos...\")\n",
    "# Usar pocos archivos por clase para SHAP, es más rápido\n",
    "# Necesitamos datos de fondo (entrenamiento) y datos de prueba (validación)\n",
    "dataset = ECGDataset(DATA_FOLDER, CLASS_FOLDERS, files_per_class=50) \n",
    "indices = list(range(len(dataset)))\n",
    "labels_arr = [dataset.samples[i][1] for i in indices]\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.5, stratify=labels_arr, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "# SHAP necesita lotes de datos\n",
    "# Un lote de fondo (background) y un lote de prueba (test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False) # Lote más pequeño para explicar\n",
    "\n",
    "# Tomar un lote de fondo (para el 'baseline' de SHAP)\n",
    "background_signals, _, _ = next(iter(train_loader))\n",
    "# Tomar un lote de prueba (los que queremos explicar)\n",
    "test_signals, test_labels, _ = next(iter(val_loader))\n",
    "\n",
    "print(f\"Background signals shape: {background_signals.shape}\")\n",
    "print(f\"Test signals shape: {test_signals.shape}\")\n",
    "\n",
    "# --- 2. Cargar Modelo ---\n",
    "print(\"Cargando modelo...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CRNN_Model(\n",
    "    n_channels_cnn=N_CHANNELS,\n",
    "    rnn_hidden_size=RNN_HIDDEN,\n",
    "    rnn_num_layers=RNN_LAYERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    bidirectional=True\n",
    ").to(device)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "except RuntimeError as e:\n",
    "    print(f\"--- ¡ERROR AL CARGAR EL MODELO! ---\")\n",
    "    print(e)\n",
    "    print(\"\\nEsto suele pasar si 'N_CHANNELS' no coincide con el modelo guardado.\")\n",
    "    print(f\"Estás intentando cargar {N_CHANNELS} canales.\")\n",
    "    print(\"Verifica el 'n_channels_cnn' en tu notebook (era 13) vs los leads de 'ECGDataset' (eran 12).\")\n",
    "    print(\"Ajusta 'N_CHANNELS' en este script para que coincida con el modelo .pth guardado.\")\n",
    "    exit() # Salir si no se puede cargar\n",
    "\n",
    "model.eval()\n",
    "print(\"Modelo cargado exitosamente.\")\n",
    "\n",
    "# --- 3. Calcular SHAP Values ---\n",
    "print(\"Calculando SHAP values (esto puede tardar)...\")\n",
    "\n",
    "# Mover datos al dispositivo\n",
    "background_signals = background_signals.to(device)\n",
    "test_signals = test_signals.to(device)\n",
    "\n",
    "# Usar DeepExplainer (bueno para PyTorch)\n",
    "# Le pasamos el modelo y los datos de fondo\n",
    "explainer = shap.GradientExplainer(model, background_signals)\n",
    "\n",
    "# Calculamos los SHAP values para los datos de prueba\n",
    "shap_values = explainer.shap_values(test_signals)\n",
    "\n",
    "print(\"Cálculo de SHAP finalizado.\")\n",
    "\n",
    "# shap_values es una lista (una por clase) de arrays\n",
    "# Cada array tiene la forma (batch_size, 12, 10000)\n",
    "print(f\"SHAP values tiene {len(shap_values)} elementos (uno por clase)\")\n",
    "print(f\"El shape de los SHAP para la clase 0 es: {shap_values[0].shape}\")\n",
    "\n",
    "\n",
    "# --- 4. Analizar Importancia por Lead ---\n",
    "print(\"\\n--- Importancia Absoluta Media por Lead ---\")\n",
    "\n",
    "# Para obtener la importancia general de cada lead, promediamos el valor absoluto\n",
    "# de SHAP a través de todas las clases, muestras y tiempo.\n",
    "# Convertimos la lista de (N_samples, N_leads, N_time) a (N_classes, N_samples, N_leads, N_time)\n",
    "shap_values_np = np.array(shap_values)\n",
    "\n",
    "# (N_classes, N_samples, N_leads, N_time) -> (N_leads)\n",
    "# Promediamos sobre clases, muestras y tiempo\n",
    "mean_abs_shap = np.mean(np.abs(shap_values_np), axis=(0, 1, 3))\n",
    "\n",
    "lead_importance = sorted(zip(LEADS, mean_abs_shap), key=lambda x: x[1], reverse=True)\n",
    "for lead, importance in lead_importance:\n",
    "    print(f\"{lead}: {importance:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c4aa9",
   "metadata": {},
   "source": [
    "--- Importancia Absoluta Media por Lead ---\n",
    "aVL: 0.000084\n",
    "V2: 0.000084\n",
    "V4: 0.000077\n",
    "V3: 0.000071\n",
    "V6: 0.000070\n",
    "aVF: 0.000066\n",
    "aVR: 0.000066\n",
    "II: 0.000065\n",
    "V1: 0.000064\n",
    "V5: 0.000062\n",
    "III: 0.000060\n",
    "I: 0.000057"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002be2b",
   "metadata": {},
   "source": [
    "Cargando datos...\n",
    "Background signals shape: torch.Size([8, 24, 10000])\n",
    "Test signals shape: torch.Size([8, 24, 10000])\n",
    "Cargando modelo...\n",
    "Modelo cargado exitosamente.\n",
    "Calculando SHAP values (esto puede tardar)...\n",
    "Cálculo de SHAP finalizado.\n",
    "SHAP values tiene 8 elementos (uno por clase)\n",
    "El shape de los SHAP para la clase 0 es: (24, 10000, 4)\n",
    "\n",
    "#### --- Importancia Absoluta Media por Lead ---\n",
    "- mp_aVR: 0.000084\n",
    "- mp_V2: 0.000082\n",
    "- V2: 0.000081\n",
    "- mp_V6: 0.000080\n",
    "- mp_aVF: 0.000080\n",
    "- V6: 0.000076\n",
    "- mp_V4: 0.000074\n",
    "- aVR: 0.000074\n",
    "- mp_V1: 0.000072\n",
    "- mp_aVL: 0.000070\n",
    "- V4: 0.000069\n",
    "- mp_II: 0.000069\n",
    "- mp_V3: 0.000066\n",
    "- mp_III: 0.000065\n",
    "- mp_V5: 0.000063\n",
    "- aVF: 0.000060\n",
    "- V3: 0.000060\n",
    "- mp_I: 0.000060\n",
    "- aVL: 0.000059\n",
    "- II: 0.000058\n",
    "- V1: 0.000057\n",
    "- III: 0.000057\n",
    "- I: 0.000054\n",
    "- V5: 0.000048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3548b39",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
