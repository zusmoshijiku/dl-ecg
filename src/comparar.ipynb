{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import neurokit2 as nk # Asumo que esto está instalado por tus nbs anteriores\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "DATA_FOLDER = 'data' # Ajusta esto a tu ruta real\n",
    "SAMPLES_PER_CLASS = 2000 # Para asegurar balanceo base\n",
    "MAX_WORKERS = -1\n",
    "PRE_DISPATCH = '2*n_jobs'\n",
    "SAMPLING_RATE = 1000\n",
    "LEADS = ['I','II','III','aVR','aVL','aVF','V1','V2','V3','V4','V5','V6']\n",
    "\n",
    "# Mapeo Maestro (Normal = 0 facilita la lógica binaria)\n",
    "CLASS_MAP = {\n",
    "    'normal': 0,\n",
    "    'arritmia': 1,\n",
    "    'block': 2,\n",
    "    'fibrilation': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TU FUNCIÓN DE EXTRACCIÓN (Copiada de tus nbs) ---\n",
    "def toFeature(signal: pd.core.frame.DataFrame, time = False):\n",
    "    time_features = [\"HRV_MeanNN\", \"HRV_SDNN\", \"HRV_RMSSD\", \"HRV_pNN50\"]\n",
    "    F = []\n",
    "    for lead in LEADS:\n",
    "        clean = nk.ecg_clean(signal[lead], sampling_rate=SAMPLING_RATE)\n",
    "        _, rpeaks = nk.ecg_peaks(clean, sampling_rate=SAMPLING_RATE)\n",
    "        rpeak_indices = rpeaks['ECG_R_Peaks']\n",
    "        # Pasar de largo si no hay suficientes R-peaks\n",
    "        if np.sum(rpeak_indices) < 2:\n",
    "            F += [np.nan, np.nan, np.nan, np.nan]\n",
    "            continue\n",
    "        try:\n",
    "            _, waves_peak = nk.ecg_delineate(clean, rpeaks, sampling_rate=SAMPLING_RATE, method=\"peak\")\n",
    "            mean_r = np.mean([clean[i] if not np.isnan(i) else 0 for i in rpeaks['ECG_R_Peaks']]) if np.any(rpeaks['ECG_R_Peaks']) else np.nan\n",
    "            mean_p = np.mean([clean[i] if not np.isnan(i) else 0 for i in waves_peak['ECG_P_Peaks']]) if 'ECG_P_Peaks' in waves_peak else np.nan\n",
    "            mean_q = np.mean([clean[i] if not np.isnan(i) else 0 for i in waves_peak['ECG_Q_Peaks']]) if 'ECG_Q_Peaks' in waves_peak else np.nan\n",
    "            mean_s = np.mean([clean[i] if not np.isnan(i) else 0 for i in waves_peak['ECG_S_Peaks']]) if 'ECG_S_Peaks' in waves_peak else np.nan\n",
    "        except Exception:\n",
    "            mean_r = mean_p = mean_q = mean_s = np.nan\n",
    "        F += [mean_r, mean_p, mean_q, mean_s]\n",
    "    # Features temporales con lead II:\n",
    "    clean2 = nk.ecg_clean(signal[\"II\"], sampling_rate=SAMPLING_RATE)\n",
    "    _, rpeaks = nk.ecg_peaks(clean2, sampling_rate=SAMPLING_RATE)\n",
    "    valid_rpeaks = [r for r in rpeaks['ECG_R_Peaks'] if not np.isnan(r)]\n",
    "    if len(valid_rpeaks) >= 2: # Seguir de largo si no hay R-peaks suficientes\n",
    "        if time:\n",
    "            t = nk.hrv_time(rpeaks, sampling_rate=SAMPLING_RATE)\n",
    "            F.extend(t[time_features].values.flatten().tolist())\n",
    "    else:\n",
    "        nan_count = 0\n",
    "        if time: nan_count += len(time_features)\n",
    "        F.extend([np.nan] * nan_count)\n",
    "    return np.array(F)\n",
    "\n",
    "def _process_file(item):\n",
    "    path, label = item\n",
    "    try:\n",
    "        df = pd.read_parquet(path, engine='fastparquet')\n",
    "        if not set(LEADS).issubset(df.columns): return None\n",
    "        df_leads = df[LEADS].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "        feat = toFeature(df_leads, time=True) \n",
    "        \n",
    "        return feat, label\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f69d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. CARGA Y PREPARACIÓN DEL DATASET MAESTRO ---\n",
    "print(\"1. Generando lista de archivos balanceada...\")\n",
    "file_items = []\n",
    "for folder, label in CLASS_MAP.items():\n",
    "    folder_path = os.path.join(DATA_FOLDER, folder)\n",
    "    paths = glob.glob(os.path.join(folder_path, '*.parquet.gzip'))\n",
    "    \n",
    "    # Manejo si no hay datos (para probar el script)\n",
    "    if not paths: \n",
    "        print(f\"Warning: No data for {folder}, skipping/mocking\")\n",
    "        continue \n",
    "\n",
    "    if len(paths) >= SAMPLES_PER_CLASS:\n",
    "        sampled = random.sample(paths, SAMPLES_PER_CLASS)\n",
    "    else:\n",
    "        sampled = random.choices(paths, k=SAMPLES_PER_CLASS) # Upsample\n",
    "    \n",
    "    file_items.extend([(p, label) for p in sampled])\n",
    "\n",
    "random.shuffle(file_items)\n",
    "\n",
    "\n",
    "# Extracción Paralela Real\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "workers = max(1, cpu_count - 1)\n",
    "results = Parallel(n_jobs=workers, backend='loky', verbose=1)(\n",
    "    delayed(_process_file)(item) for item in file_items\n",
    ")\n",
    "\n",
    "# Limpieza\n",
    "valid_results = [r for r in results if r is not None]\n",
    "X_raw = np.vstack([r[0] for r in valid_results])\n",
    "y_all = np.array([r[1] for r in valid_results])\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_raw)\n",
    "\n",
    "print(f\"Dataset Maestro: X={X_imputed.shape}, y={y_all.shape}\")\n",
    "\n",
    "# --- 2. SPLIT SAGRADO (El mismo test set para ambos) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- ESTRATEGIA 1: RANDOM FOREST MULTICLASE (PLANO) ---\n",
    "print(\"\\n--- Estrategia 1: Multiclase Directa ---\")\n",
    "rf_flat = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n",
    "rf_flat.fit(X_train, y_train)\n",
    "\n",
    "y_pred_flat = rf_flat.predict(X_test)\n",
    "acc_flat = accuracy_score(y_test, y_pred_flat)\n",
    "print(f\"Accuracy (Plano): {acc_flat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5338503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- ESTRATEGIA 2: JERÁRQUICA (NORMAL vs ANORMAL -> CLASIFICAR ANORMAL) ---\n",
    "print(\"\\n--- Estrategia 2: Jerárquica (Segmentada) ---\")\n",
    "\n",
    "# Paso 2.1: Preparar datos para Fase 1 (Binaria)\n",
    "# 0 = Normal, 1 = Anormal (Arritmia, Block, Fib)\n",
    "y_train_binary = (y_train != 0).astype(int) \n",
    "# Nota: En train tenemos 25% normal y 75% anormal. \n",
    "# Es VITAL usar class_weight='balanced' para que no se sesgue a predecir siempre \"Anormal\".\n",
    "\n",
    "rf_binary = RandomForestClassifier(n_estimators=1000, class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "rf_binary.fit(X_train, y_train_binary)\n",
    "\n",
    "# Paso 2.2: Preparar datos para Fase 2 (Solo Anormales)\n",
    "# Filtramos el set de entrenamiento para quedarnos solo con las patologías\n",
    "mask_anormal_train = y_train != 0\n",
    "X_train_sub = X_train[mask_anormal_train]\n",
    "y_train_sub = y_train[mask_anormal_train]\n",
    "\n",
    "rf_subclass = RandomForestClassifier(n_estimators=1000, class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "rf_subclass.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# Paso 2.3: Inferencia Jerárquica sobre X_test (La lógica de combinación)\n",
    "# Primero, predecimos si es normal o anormal\n",
    "y_pred_binary_test = rf_binary.predict(X_test)\n",
    "\n",
    "# Creamos un array para guardar las predicciones finales\n",
    "y_pred_hierarchical = np.zeros_like(y_pred_binary_test)\n",
    "\n",
    "# Caso A: Si el modelo binario dice \"Normal\" (0), la predicción final es 0 (Normal)\n",
    "# (Esto ya está hecho porque inicializamos con ceros, pero es conceptual)\n",
    "y_pred_hierarchical[y_pred_binary_test == 0] = 0 \n",
    "\n",
    "# Caso B: Si el modelo binario dice \"Anormal\" (1), pasamos esos datos al modelo subclase\n",
    "mask_pred_anormal = y_pred_binary_test == 1\n",
    "\n",
    "if np.any(mask_pred_anormal):\n",
    "    # Solo predecimos sobre los que pasaron el primer filtro\n",
    "    subclass_predictions = rf_subclass.predict(X_test[mask_pred_anormal])\n",
    "    y_pred_hierarchical[mask_pred_anormal] = subclass_predictions\n",
    "\n",
    "# Evaluación\n",
    "acc_hier = accuracy_score(y_test, y_pred_hierarchical)\n",
    "print(f\"Accuracy (Jerárquico): {acc_hier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- COMPARACIÓN FINAL ---\n",
    "print(\"\\n=== RESULTADOS FINALES ===\")\n",
    "print(f\"Estrategia 1 (Plano):      {acc_flat:.4f}\")\n",
    "print(f\"Estrategia 2 (Jerárquico): {acc_hier:.4f}\")\n",
    "\n",
    "print(\"\\nDetalle Estrategia 1:\")\n",
    "print(classification_report(y_test, y_pred_flat, target_names=list(CLASS_MAP.keys())))\n",
    "\n",
    "print(\"\\nDetalle Estrategia 2:\")\n",
    "print(classification_report(y_test, y_pred_hierarchical, target_names=list(CLASS_MAP.keys())))\n",
    "\n",
    "# Matriz de confusión para entender errores de la jerárquica\n",
    "# Ver si el error viene de confundir Normal con Anormal, o de confundir patologías entre sí\n",
    "print(\"\\nMatriz de Confusión (Jerárquica):\")\n",
    "print(confusion_matrix(y_test, y_pred_hierarchical))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
