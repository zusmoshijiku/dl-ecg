{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001d6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import neurokit2 as nk \n",
    "\n",
    "DATA_FOLDER = 'data'\n",
    "SAMPLES_PER_CLASS = 1970 \n",
    "MAX_WORKERS = -1\n",
    "PRE_DISPATCH = '2*n_jobs'\n",
    "SAMPLING_RATE = 1000\n",
    "LEADS = ['I','II','III','aVR','aVL','aVF','V1','V2','V3','V4','V5','V6']\n",
    "\n",
    "CLASS_MAP = {\n",
    "    'normal': 0,\n",
    "    'arritmia': 1,\n",
    "    'block': 2,\n",
    "    'fibrilation': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6988456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFeature(signal: pd.core.frame.DataFrame, time = False):\n",
    "    time_features = [\"HRV_MeanNN\", \"HRV_SDNN\", \"HRV_RMSSD\", \"HRV_pNN50\"]\n",
    "    F = []\n",
    "    for lead in LEADS:\n",
    "        clean = nk.ecg_clean(signal[lead], sampling_rate=SAMPLING_RATE)\n",
    "        _, rpeaks = nk.ecg_peaks(clean, sampling_rate=SAMPLING_RATE)\n",
    "        rpeak_indices = rpeaks['ECG_R_Peaks']\n",
    "        # Pasar de largo si no hay suficientes R-peaks\n",
    "        if np.sum(rpeak_indices) < 2:\n",
    "            F += [np.nan, np.nan, np.nan, np.nan]\n",
    "            continue\n",
    "        try:\n",
    "            _, waves_peak = nk.ecg_delineate(clean, rpeaks, sampling_rate=SAMPLING_RATE, method=\"peak\")\n",
    "            mean_r = np.mean([clean[i] if not np.isnan(i) else 0 for i in rpeaks['ECG_R_Peaks']]) if np.any(rpeaks['ECG_R_Peaks']) else np.nan\n",
    "            mean_p = np.mean([clean[i] if not np.isnan(i) else 0 for i in waves_peak['ECG_P_Peaks']]) if 'ECG_P_Peaks' in waves_peak else np.nan\n",
    "            mean_q = np.mean([clean[i] if not np.isnan(i) else 0 for i in waves_peak['ECG_Q_Peaks']]) if 'ECG_Q_Peaks' in waves_peak else np.nan\n",
    "            mean_s = np.mean([clean[i] if not np.isnan(i) else 0 for i in waves_peak['ECG_S_Peaks']]) if 'ECG_S_Peaks' in waves_peak else np.nan\n",
    "        except Exception:\n",
    "            mean_r = mean_p = mean_q = mean_s = np.nan\n",
    "        F += [mean_r, mean_p, mean_q, mean_s]\n",
    "    # Features temporales con lead II:\n",
    "    clean2 = nk.ecg_clean(signal[\"II\"], sampling_rate=SAMPLING_RATE)\n",
    "    _, rpeaks = nk.ecg_peaks(clean2, sampling_rate=SAMPLING_RATE)\n",
    "    valid_rpeaks = [r for r in rpeaks['ECG_R_Peaks'] if not np.isnan(r)]\n",
    "    if len(valid_rpeaks) >= 2: # Seguir de largo si no hay R-peaks suficientes\n",
    "        if time:\n",
    "            t = nk.hrv_time(rpeaks, sampling_rate=SAMPLING_RATE)\n",
    "            F.extend(t[time_features].values.flatten().tolist())\n",
    "    else:\n",
    "        nan_count = 0\n",
    "        if time: nan_count += len(time_features)\n",
    "        F.extend([np.nan] * nan_count)\n",
    "    return np.array(F)\n",
    "\n",
    "def _process_file(item):\n",
    "    path, label = item\n",
    "    try:\n",
    "        df = pd.read_parquet(path, engine='fastparquet')\n",
    "        if not set(LEADS).issubset(df.columns): return None\n",
    "        df_leads = df[LEADS].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "        feat = toFeature(df_leads, time=True) \n",
    "        \n",
    "        return feat, label\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f69d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=7)]: Done 4036 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=7)]: Done 4986 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=7)]: Done 6036 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=7)]: Done 7186 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=7)]: Done 7880 out of 7880 | elapsed: 41.2min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_items = []\n",
    "for folder, label in CLASS_MAP.items():\n",
    "    folder_path = os.path.join(DATA_FOLDER, folder)\n",
    "    paths = glob.glob(os.path.join(folder_path, '*.parquet.gzip'))\n",
    "    if not paths: \n",
    "        print(f\"Warning: No data for {folder}, skipping\")\n",
    "        continue \n",
    "\n",
    "    if len(paths) >= SAMPLES_PER_CLASS:\n",
    "        sampled = random.sample(paths, SAMPLES_PER_CLASS)\n",
    "    else:\n",
    "        sampled = random.choices(paths, k=SAMPLES_PER_CLASS)\n",
    "    \n",
    "    file_items.extend([(p, label) for p in sampled])\n",
    "\n",
    "random.shuffle(file_items)\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "workers = max(1, cpu_count - 1)\n",
    "results = Parallel(n_jobs=workers, backend='loky', verbose=1)(\n",
    "    delayed(_process_file)(item) for item in file_items\n",
    ")\n",
    "valid_results = [r for r in results if r is not None]\n",
    "X_raw = np.vstack([r[0] for r in valid_results])\n",
    "y_all = np.array([r[1] for r in valid_results])\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_raw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc27e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Estrategia 1: Multiclase Directa ---\n",
      "Accuracy (Plano): 0.8319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Estrategia 1: Multiclase Directa ---\")\n",
    "rf_flat = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "rf_flat.fit(X_train, y_train)\n",
    "\n",
    "y_pred_flat = rf_flat.predict(X_test)\n",
    "acc_flat = accuracy_score(y_test, y_pred_flat)\n",
    "print(f\"Accuracy (Plano): {acc_flat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5338503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Estrategia 2: Jerárquica (Segmentada) ---\n",
      "Accuracy (Jerárquico): 0.8096\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Estrategia 2: Jerárquica (Segmentada) ---\")\n",
    "\n",
    "y_train_binary = (y_train != 0).astype(int) \n",
    "\n",
    "rf_binary = RandomForestClassifier(n_estimators=1000, class_weight='balanced', n_jobs=-1)\n",
    "rf_binary.fit(X_train, y_train_binary)\n",
    "\n",
    "mask_anormal_train = y_train != 0\n",
    "X_train_sub = X_train[mask_anormal_train]\n",
    "y_train_sub = y_train[mask_anormal_train]\n",
    "\n",
    "rf_subclass = RandomForestClassifier(n_estimators=1000, class_weight='balanced', n_jobs=-1)\n",
    "rf_subclass.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "y_pred_binary_test = rf_binary.predict(X_test)\n",
    "y_pred_hierarchical = np.zeros_like(y_pred_binary_test)\n",
    "y_pred_hierarchical[y_pred_binary_test == 0] = 0 \n",
    "mask_pred_anormal = y_pred_binary_test == 1\n",
    "\n",
    "if np.any(mask_pred_anormal):\n",
    "    subclass_predictions = rf_subclass.predict(X_test[mask_pred_anormal])\n",
    "    y_pred_hierarchical[mask_pred_anormal] = subclass_predictions\n",
    "\n",
    "acc_hier = accuracy_score(y_test, y_pred_hierarchical)\n",
    "print(f\"Accuracy (Jerárquico): {acc_hier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11bc1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrategia 1 (Plano):      0.8319\n",
      "Estrategia 2 (Jerárquico): 0.8096\n",
      "\n",
      "Detalle Estrategia 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.87      0.86      0.86       394\n",
      "    arritmia       0.87      0.86      0.86       394\n",
      "       block       0.76      0.79      0.77       394\n",
      " fibrilation       0.84      0.82      0.83       394\n",
      "\n",
      "    accuracy                           0.83      1576\n",
      "   macro avg       0.83      0.83      0.83      1576\n",
      "weighted avg       0.83      0.83      0.83      1576\n",
      "\n",
      "\n",
      "Detalle Estrategia 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.88      0.75      0.81       394\n",
      "    arritmia       0.83      0.86      0.84       394\n",
      "       block       0.71      0.82      0.76       394\n",
      " fibrilation       0.83      0.82      0.83       394\n",
      "\n",
      "    accuracy                           0.81      1576\n",
      "   macro avg       0.82      0.81      0.81      1576\n",
      "weighted avg       0.82      0.81      0.81      1576\n",
      "\n",
      "\n",
      "Matriz de Confusión (Jerárquica):\n",
      "[[294  48  42  10]\n",
      " [ 24 337  22  11]\n",
      " [ 15  14 322  43]\n",
      " [  0   6  65 323]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estrategia 1 (Plano):      {acc_flat:.4f}\")\n",
    "print(f\"Estrategia 2 (Jerárquico): {acc_hier:.4f}\")\n",
    "\n",
    "print(\"\\nDetalle Estrategia 1:\")\n",
    "print(classification_report(y_test, y_pred_flat, target_names=list(CLASS_MAP.keys())))\n",
    "\n",
    "print(\"\\nDetalle Estrategia 2:\")\n",
    "print(classification_report(y_test, y_pred_hierarchical, target_names=list(CLASS_MAP.keys())))\n",
    "\n",
    "print(\"\\nMatriz de Confusión (Jerárquica):\")\n",
    "print(confusion_matrix(y_test, y_pred_hierarchical))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
