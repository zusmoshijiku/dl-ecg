{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3022a283",
   "metadata": {},
   "source": [
    "# ECG Heart Disease Detection with Deep Learning\n",
    "\n",
    "This notebook serves as a comprehensive guide for learning Docker and PyTorch to analyze ECG datasets for heart disease detection using deep learning algorithms.\n",
    "\n",
    "## Project Overview\n",
    "- **Dataset**: ~500,000 ECG recordings\n",
    "- **Task**: Testing different deep learning algorithms for heart disease detection\n",
    "- **Tools**: Docker, PyTorch, ECG analysis libraries\n",
    "- **Goal**: Compare performance of various DL models for cardiovascular disease detection\n",
    "\n",
    "## Learning Objectives\n",
    "1. Master Docker container management for data science workflows\n",
    "2. Understand ECG signal processing and analysis\n",
    "3. Implement multiple deep learning architectures in PyTorch\n",
    "4. Evaluate and compare model performance for medical diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcab4a",
   "metadata": {},
   "source": [
    "## 1. Docker Container Setup and Management\n",
    "\n",
    "Understanding Docker is essential for reproducible research environments and working with the professor's dataset container.\n",
    "\n",
    "### Essential Docker Commands for ECG Analysis\n",
    "\n",
    "Let's learn the key Docker commands you'll need for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f10c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker commands you'll need (run these in terminal/command prompt)\n",
    "\n",
    "# 1. Build your development container\n",
    "# docker build -t ecg-analysis .\n",
    "\n",
    "# 2. Run container with Jupyter notebook\n",
    "# docker run -p 8888:8888 -v $(pwd)/data:/app/data ecg-analysis\n",
    "\n",
    "# 3. Run container interactively for development\n",
    "# docker run -it -v $(pwd):/app ecg-analysis bash\n",
    "\n",
    "# 4. List running containers\n",
    "# docker ps\n",
    "\n",
    "# 5. Stop a container\n",
    "# docker stop <container_id>\n",
    "\n",
    "# 6. Remove unused containers and images\n",
    "# docker system prune\n",
    "\n",
    "print(\"Docker setup commands ready!\")\n",
    "print(\"Remember to:\")\n",
    "print(\"1. Build the container: docker build -t ecg-analysis .\")\n",
    "print(\"2. Run with data volume: docker run -p 8888:8888 -v $(pwd)/data:/app/data ecg-analysis\")\n",
    "print(\"3. Access Jupyter at: http://localhost:8888\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e7e35",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading and Exploration\n",
    "\n",
    "Once you receive the professor's container with the ECG dataset, you'll need to explore its structure and understand the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56829734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths for ECG data\n",
    "DATA_PATH = \"/app/data\"  # Path inside Docker container\n",
    "LOCAL_DATA_PATH = \"./data\"  # Local development path\n",
    "\n",
    "# Check if we're running in container or locally\n",
    "if os.path.exists(DATA_PATH):\n",
    "    data_path = DATA_PATH\n",
    "    print(\"Running in Docker container\")\n",
    "else:\n",
    "    data_path = LOCAL_DATA_PATH\n",
    "    print(\"Running locally\")\n",
    "\n",
    "print(f\"Data path: {data_path}\")\n",
    "\n",
    "# Explore the dataset structure\n",
    "def explore_dataset(data_path):\n",
    "    \"\"\"Explore the ECG dataset structure\"\"\"\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Data directory {data_path} not found\")\n",
    "        print(\"This will work once you mount the professor's dataset\")\n",
    "        return\n",
    "    \n",
    "    print(\"Dataset exploration:\")\n",
    "    print(f\"Total files: {len(list(Path(data_path).rglob('*')))}\")\n",
    "    \n",
    "    # Look for common ECG file formats\n",
    "    formats = ['.dat', '.hea', '.atr', '.csv', '.h5', '.npz']\n",
    "    for fmt in formats:\n",
    "        files = list(Path(data_path).rglob(f'*{fmt}'))\n",
    "        if files:\n",
    "            print(f\"{fmt} files: {len(files)}\")\n",
    "    \n",
    "    # List directory structure\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        level = root.replace(data_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Show first 5 files\n",
    "            print(f\"{subindent}{file}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{subindent}... and {len(files) - 5} more files\")\n",
    "\n",
    "explore_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75478a09",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing for ECG Signals\n",
    "\n",
    "ECG signals require specific preprocessing steps to ensure good model performance. This includes normalization, filtering, and handling different signal lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "import neurokit2 as nk\n",
    "\n",
    "# ECG Preprocessing Functions\n",
    "\n",
    "def bandpass_filter(ecg_signal, lowcut=0.5, highcut=40, fs=500, order=4):\n",
    "    \"\"\"\n",
    "    Apply bandpass filter to remove noise from ECG signal\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_signal = filtfilt(b, a, ecg_signal)\n",
    "    return filtered_signal\n",
    "\n",
    "def normalize_ecg(ecg_signal, method='z-score'):\n",
    "    \"\"\"\n",
    "    Normalize ECG signal using different methods\n",
    "    \"\"\"\n",
    "    if method == 'z-score':\n",
    "        return (ecg_signal - np.mean(ecg_signal)) / (np.std(ecg_signal) + 1e-8)\n",
    "    elif method == 'min-max':\n",
    "        return (ecg_signal - np.min(ecg_signal)) / (np.max(ecg_signal) - np.min(ecg_signal) + 1e-8)\n",
    "    elif method == 'robust':\n",
    "        median = np.median(ecg_signal)\n",
    "        mad = np.median(np.abs(ecg_signal - median))\n",
    "        return (ecg_signal - median) / (mad + 1e-8)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'z-score', 'min-max', or 'robust'\")\n",
    "\n",
    "def pad_or_truncate(signal, target_length=5000):\n",
    "    \"\"\"\n",
    "    Ensure all signals have the same length\n",
    "    \"\"\"\n",
    "    if len(signal) > target_length:\n",
    "        # Truncate from the center\n",
    "        start = (len(signal) - target_length) // 2\n",
    "        return signal[start:start + target_length]\n",
    "    elif len(signal) < target_length:\n",
    "        # Pad with zeros\n",
    "        padding = target_length - len(signal)\n",
    "        pad_left = padding // 2\n",
    "        pad_right = padding - pad_left\n",
    "        return np.pad(signal, (pad_left, pad_right), mode='constant', constant_values=0)\n",
    "    return signal\n",
    "\n",
    "def detect_r_peaks(ecg_signal, fs=500):\n",
    "    \"\"\"\n",
    "    Detect R-peaks in ECG signal using NeuroKit2\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the signal first\n",
    "        cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=fs)\n",
    "        \n",
    "        # Find R-peaks\n",
    "        peaks, info = nk.ecg_peaks(cleaned_ecg, sampling_rate=fs)\n",
    "        \n",
    "        return peaks['ECG_R_Peaks'], cleaned_ecg\n",
    "    except:\n",
    "        print(\"Warning: R-peak detection failed\")\n",
    "        return [], ecg_signal\n",
    "\n",
    "# Example preprocessing pipeline\n",
    "def preprocess_ecg_signal(signal, fs=500, target_length=5000):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for ECG signals\n",
    "    \"\"\"\n",
    "    # 1. Bandpass filter\n",
    "    filtered_signal = bandpass_filter(signal, fs=fs)\n",
    "    \n",
    "    # 2. Normalize\n",
    "    normalized_signal = normalize_ecg(filtered_signal, method='z-score')\n",
    "    \n",
    "    # 3. Ensure consistent length\n",
    "    processed_signal = pad_or_truncate(normalized_signal, target_length)\n",
    "    \n",
    "    return processed_signal\n",
    "\n",
    "# Generate synthetic ECG for demonstration\n",
    "def generate_synthetic_ecg(length=5000, fs=500, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generate a synthetic ECG signal for testing\n",
    "    \"\"\"\n",
    "    t = np.arange(length) / fs\n",
    "    \n",
    "    # Basic ECG pattern (simplified)\n",
    "    ecg = np.zeros(length)\n",
    "    heart_rate = 72  # BPM\n",
    "    beat_interval = fs * 60 / heart_rate\n",
    "    \n",
    "    for i in range(int(length / beat_interval)):\n",
    "        beat_start = int(i * beat_interval)\n",
    "        if beat_start + 100 < length:\n",
    "            # Simplified QRS complex\n",
    "            ecg[beat_start:beat_start+20] = np.sin(np.linspace(0, np.pi, 20)) * 0.5\n",
    "            ecg[beat_start+20:beat_start+40] = np.sin(np.linspace(0, 2*np.pi, 20)) * 1.5\n",
    "            ecg[beat_start+40:beat_start+60] = np.sin(np.linspace(0, np.pi, 20)) * -0.8\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, noise_level, length)\n",
    "    ecg += noise\n",
    "    \n",
    "    return ecg, t\n",
    "\n",
    "# Test preprocessing\n",
    "print(\"Testing ECG preprocessing pipeline...\")\n",
    "synthetic_ecg, time_axis = generate_synthetic_ecg()\n",
    "processed_ecg = preprocess_ecg_signal(synthetic_ecg)\n",
    "\n",
    "print(f\"Original signal shape: {synthetic_ecg.shape}\")\n",
    "print(f\"Processed signal shape: {processed_ecg.shape}\")\n",
    "print(f\"Signal stats - Mean: {np.mean(processed_ecg):.4f}, Std: {np.std(processed_ecg):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c99c59",
   "metadata": {},
   "source": [
    "## 4. PyTorch Environment Setup\n",
    "\n",
    "Let's set up PyTorch and understand the basic operations you'll need for deep learning with ECG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Check PyTorch setup\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Basic PyTorch operations for ECG data\n",
    "def torch_basics_demo():\n",
    "    \"\"\"Demonstrate basic PyTorch operations relevant to ECG analysis\"\"\"\n",
    "    \n",
    "    # Create a tensor representing ECG signals (batch_size, signal_length)\n",
    "    batch_size = 4\n",
    "    signal_length = 5000\n",
    "    \n",
    "    # Random ECG-like data\n",
    "    ecg_batch = torch.randn(batch_size, signal_length, device=device)\n",
    "    print(f\"ECG batch shape: {ecg_batch.shape}\")\n",
    "    \n",
    "    # Create labels (0: normal, 1: disease)\n",
    "    labels = torch.randint(0, 2, (batch_size,), device=device)\n",
    "    print(f\"Labels: {labels}\")\n",
    "    \n",
    "    # Basic operations\n",
    "    print(f\"Mean: {torch.mean(ecg_batch, dim=1)}\")  # Mean per signal\n",
    "    print(f\"Std: {torch.std(ecg_batch, dim=1)}\")    # Std per signal\n",
    "    \n",
    "    # Normalize each signal in the batch\n",
    "    normalized_batch = (ecg_batch - torch.mean(ecg_batch, dim=1, keepdim=True)) / \\\n",
    "                      (torch.std(ecg_batch, dim=1, keepdim=True) + 1e-8)\n",
    "    \n",
    "    print(f\"Normalized mean: {torch.mean(normalized_batch, dim=1)}\")\n",
    "    \n",
    "    return ecg_batch, labels\n",
    "\n",
    "# Custom Dataset class for ECG data\n",
    "class ECGDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for ECG signals\"\"\"\n",
    "    \n",
    "    def __init__(self, signals, labels, transform=None):\n",
    "        self.signals = torch.FloatTensor(signals)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.signals[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            signal = self.transform(signal)\n",
    "        \n",
    "        return signal, label\n",
    "\n",
    "# Test PyTorch setup\n",
    "print(\"Testing PyTorch setup...\")\n",
    "ecg_batch, labels = torch_basics_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b7808",
   "metadata": {},
   "source": [
    "## 5. Basic Neural Network Implementation\n",
    "\n",
    "Let's start with a simple feedforward neural network as a baseline for ECG classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicECGClassifier(nn.Module):\n",
    "    \"\"\"Simple feedforward neural network for ECG classification\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=5000, hidden_sizes=[512, 256, 128], num_classes=2, dropout_rate=0.5):\n",
    "        super(BasicECGClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the input if needed\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        return self.network(x)\n",
    "\n",
    "# Create and test the basic model\n",
    "def test_basic_model():\n",
    "    model = BasicECGClassifier(input_size=5000, num_classes=2).to(device)\n",
    "    \n",
    "    # Test with random data\n",
    "    batch_size = 4\n",
    "    test_input = torch.randn(batch_size, 5000).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(test_input)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "    \n",
    "    print(f\"Model output shape: {output.shape}\")\n",
    "    print(f\"Sample predictions: {probabilities}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Training function for basic model\n",
    "def train_basic_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
    "    \"\"\"Train the basic neural network\"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    return train_losses, val_accuracies\n",
    "\n",
    "# Test the basic model\n",
    "print(\"Testing basic neural network...\")\n",
    "basic_model = test_basic_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
